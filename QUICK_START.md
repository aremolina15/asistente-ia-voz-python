# ğŸ¯ Referencia RÃ¡pida - Asistente de Voz DevOps

## âš¡ Inicio RÃ¡pido

```bash
# Terminal 1: Servidor
cd $PROJECT_DIR  # Cambia a tu directorio del proyecto
source venv/bin/activate
python -m uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload

# Terminal 2: Cliente
cd $PROJECT_DIR  # Cambia a tu directorio del proyecto
python voice_client.py
```

## ğŸ¤ CÃ³mo Usar

1. **Sistema inicia:** Ver mensaje `ğŸ¤ Sistema listo. Habla ahora...`
2. **Hablar:** Di tu pregunta/comando
3. **Silencio:** Espera 2.5 segundos despuÃ©s de terminar
4. **Sistema procesa:** VerÃ¡s `â¸ï¸ Esperando respuesta de la IA...`
5. **Responde:** Se escucha audio con la respuesta
6. **Vuelve a escuchar:** AutomÃ¡ticamente disponible
7. **Repetir:** Habla nuevamente

## ğŸ“¢ Ejemplos de Comandos

### Preguntas (Se agrega `?`)
```
"QuÃ© es Terraform"           â†’ "QuÃ© es Terraform?"
"CÃ³mo despliego en GCP"      â†’ "CÃ³mo despliego en GCP?"
"DÃ³nde configuro un firewall" â†’ "DÃ³nde configuro un firewall?"
"Por quÃ© falla mi deployment" â†’ "Por quÃ© falla mi deployment?"
```

### Comandos (Se agrega `.`)
```
"Instala Docker"             â†’ "Instala Docker."
"Crea un cluster en Kubernetes" â†’ "Crea un cluster en Kubernetes."
"Ejecuta el pipeline"        â†’ "Ejecuta el pipeline."
```

## ğŸ“Š LÃ­nea de Tiempo

```
T=0s:    ğŸ¤ Grabando... habla ahora
T=1s:    [Usuario habla]
T=5s:    âœ‹ Fin de solicitud detectado (silencio detectado)
T=5.5s:  â³ Enviando a procesar...
T=5.5s:  â¸ï¸ Esperando respuesta de la IA...
T=6s:    ğŸ“ Transcribiendo...
T=7s:    ğŸ‘¤ TÃº: [pregunta limpia]
T=7.5s:  ğŸ¤– Procesando...
T=9s:    ğŸ—£ï¸ Asistente: [respuesta]
T=9.5s:  ğŸ”Š Reproduciendo audio...
T=15s:   âœ… Respuesta completada
T=15s:   ğŸ¤ Sistema listo. Habla ahora...
```

## ğŸ”§ ParÃ¡metros Ajustables

### En `voice_client.py` lÃ­nea 20

```python
# Actual (normal):
record_audio_continuous(silence_threshold=0.012, silence_duration=2.5)

# Silencioso:
record_audio_continuous(silence_threshold=0.010, silence_duration=2.0)

# Ruidoso:
record_audio_continuous(silence_threshold=0.015, silence_duration=3.0)
```

### Variables de entorno

```bash
export GOOGLE_APPLICATION_CREDENTIALS="/ruta/al/archivo.json"
export GOOGLE_CLOUD_PROJECT="tu-proyecto-gcp"
export VERTEX_AI_MODEL="gemini-2.0-flash"  # o gemini-2.5-flash
```

## âœ… Verificaciones

### Â¿El servidor estÃ¡ corriendo?
```bash
curl http://localhost:8000/health
# Debe responder: {"status":"healthy",...}
```

### Â¿Los endpoints funcionan?
```bash
./test_endpoints.sh
# Prueba /synthesize y /query
```

### Â¿Las credenciales estÃ¡n OK?
```bash
ls -la "$GOOGLE_APPLICATION_CREDENTIALS"
# Debe existir el archivo
```

## ğŸ› SoluciÃ³n de Problemas

| Problema | SoluciÃ³n |
|----------|----------|
| **Servidor no inicia** | `lsof -ti:8000 \| xargs -r kill -9` |
| **No se escucha audio** | Subir volumen con `alsamixer` |
| **IA no responde** | Verificar credenciales GCP |
| **Silencio no detecta** | Aumentar `silence_threshold` a 0.015 |
| **Interrupciones** | Aumentar `silence_duration` a 3.0 |

## ğŸ“ Archivos Principales

| Archivo | PropÃ³sito |
|---------|-----------|
| `voice_client.py` | Cliente con escucha continua |
| `src/main.py` | Servidor FastAPI |
| `src/config.py` | ConfiguraciÃ³n GCP |
| `src/services/gcp_service.py` | IntegraciÃ³n VertexAI/STT/TTS |
| `src/routers/voice.py` | Endpoints de voz |

## ğŸ”„ Flujo de Datos

```
MicrÃ³fono
   â†“
record_audio_continuous()    â† Captura con silencio
   â†“
/api/v1/voice/transcribe     â† Speech-to-Text (GCP)
   â†“
clean_transcription()        â† Normaliza texto
   â†“
/api/v1/voice/query          â† VertexAI Gemini (procesa)
   â†“
Text-to-Speech (GCP)         â† SÃ­ntesis de voz
   â†“
ffplay response.mp3          â† ReproducciÃ³n
   â†“
Altavoces
```

## ğŸ’¡ Tips

1. **Habla claramente** - Mejor transcripciÃ³n
2. **Frases cortas** - MÃ¡s rÃ¡pido procesamiento
3. **Temas DevOps** - IA enfocada en eso
4. **Espera silencio** - No interrumpas procesamiento
5. **Ctrl+C limpio** - Cierra correctamente

## ğŸ“ˆ CaracterÃ­sticas

âœ… Escucha continua
âœ… DetecciÃ³n inteligente de silencio (2.5s)
âœ… ComprensiÃ³n de lenguaje natural
âœ… Preguntas y comandos
âœ… Respuesta automÃ¡tica en voz
âœ… SincronizaciÃ³n sin interrupciones
âœ… Soporte para espaÃ±ol
âœ… IntegraciÃ³n VertexAI Gemini

## ğŸ“ Stack TecnolÃ³gico

- **Backend:** FastAPI + Python 3.12
- **Audio:** sounddevice, soundfile, ffmpeg
- **GCP:** Speech-to-Text, Text-to-Speech, VertexAI
- **Modelo:** Gemini 2.0 Flash
- **Concurrencia:** Threading (queue, event)

---

**VersiÃ³n:** 2.1
**Estado:** âœ… ProducciÃ³n
**Ãšltimo update:** 22 enero 2026
